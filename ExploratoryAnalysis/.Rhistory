install.packages("data.table")
library(data.table)
set.seed(123)
DT <- data.table(x=sample(letters[1:3],1E5,TRUE))
DT
DT[, .N, by=x]
y <- DT[, .N, by=x]
class(y)
sum(y[,"N"])
y
y$N
sum(y$N)
doc <- fread(""./data/data4.csv"")
doc <- fread("./data/data4.csv")
names(doc)
timep <- c("0min", "1min", "3min", "5min", "7min", "10min")
prop <- c(0, 0.3, 0.5, 0.75, 0.85, 0.9, 0.95)
windows()
plot(timep, prop)
prop <- c(0, 0.3, 0.5, 0.75, 0.9, 0.95)
plot(timep, prop)
plot(timep, prop, ylab="Proportion of polarized cells", xlab=NA)
plot(timep, prop, ylab="Proportion of polarized cells",axes =FALSE, xlab=NA)
plot(prop, ylab="Proportion of polarized cells",axes =FALSE, xlab=NA)
plot(prop, ylab="Proportion of polarized cells",axes =FALSE, xlab=NA,pCh = 20)
?plot
plot(prop, ylab="Proportion of polarized cells",axes =FALSE, xlab=NA)
?axis
axis(1, at=1:6, labels = timep)
axis(2)
axis(2, at=c(0, 0.2, 0.4, 0.6, 0.8, 1.0))
axis(2, at=c(0, 0.2, 0.4, 0.6, 0.8, 1.0), labels =c(0, 0.2, 0.4, 0.6, 0.8, 1.0) )
windows()
plot(prop, ylab="Proportion of polarized cells",axes =FALSE, xlab=NA, pch=19)
axis(1, at=1:6, labels = timep)
axis(2, at=c(0, 0.2, 0.4, 0.6, 0.8, 1.0), labels =c(0, 0.2, 0.4, 0.6, 0.8, 1.0))
install.packages(manipulate)
install.packages("manipulate")
library(manipulate)
library(UsingR)
library(manipulate)
myHist <- function(mu){
hist(galton$child, col = "blue", breaks = 100)
lines(c(mu,mu), c(0,150), col = "red", lwd = 5)
mse <- mean((galton$child - mu)^2)
text(63, 150, paste("mu = ", mu))
text(63, 140, paste("MSE = ", round(mse, 2)))
}
manipulate(myHist(mu), mu = slider(62, 74, step = 0.5))
manipulate(myHist(mu), mu = slider(62, 74, step = 0.5))
manipulate(myHist(mu), mu = slider(62, 74, step = 0.5))
lm(I(child-mean(child)) ~ I(parent-mean(parent))-1, dalton)
lm(I(child-mean(child)) ~ I(parent-mean(parent))-1, galton)
source("http://bioconductor.org/workflows.R")
workflowInstall("highthroughputassays")
library(highthroughputassays)
library(flowCore)
library(flowStats)
library(flowViz) # for flow data visualization
source("http://bioconductor.org/biocLite.R")
biocLite()
source("http://bioconductor.org/workflows.R")
workflowInstall("highthroughputassays")
bioLite()
source("http://bioconductor.org/biocLite.R")
biocLite()
bioLite("highthroughputassays")
biocLite("highthroughputassays")
biocLite(c("GenomicFeatures", "AnnotationDbi"))
workflowInstall("highthroughputassays")
?set.seed
expo_mean <- sapply(1:1000, mean(rexp(40, lamda)))
lambda <- 0.2
expo_mean <- sapply(1:1000, mean(rexp(40, lamda)))
lambda <- 0.2
expo_mean <- sapply(1:1000, mean(rexp(40, lambda)))
lambda <- 0.2
exp_sample = NULL
for (i in 1:1000) exp_sample <- c(exp_sample, rexp(40, lambda))
exp_sample
typeof(exp_sample)
str(exp_sample)
?runif
lambda <- 0.2
exp_mns = NULL
for (i in 1:1000) exp_mns <- c(exp_mns, mean(rexp(40, lambda)))
exp_mns
?var
5/sqrt(40)
5/40
25/40
?qplot
library(ggplot2)
?qplot
install.packages("rmarkdown")
library(datasets)
data(ToothGrowth)
str(ToothGrowth)
ToothGrowth$dose
unique(ToothGrowth$dose)
View(ToothGrowth)
View(ToothGrowth)
summary(ToothGrowth$len)
str(summary(ToothGrowth$len))
summary(ToothGrowth$len).min
summary(ToothGrowth$len).Min.
summary(ToothGrowth$len)$Min.
ToothGrowth[ToothGrowth$supp=="VC"&ToothGrowth$dose==0.5]
ToothGrowth[ToothGrowth$supp=="VC"&ToothGrowth$dose==0.5,]
ToothGrowth[ToothGrowth$supp=="VC"&ToothGrowth$dose==0.5, 'len']
library(ggplot2)
?geom_point
?sd
?ttest
?t.test
t.test(ToothGrowth[ToothGrowth$supp=="VC"&ToothGrowth$dose==0.5, 'len'],ToothGrowth[ToothGrowth$supp=="OJ"&ToothGrowth$dose==0.5, 'len'])
7.98-13.23
p = t.test(ToothGrowth[ToothGrowth$supp=="VC"&ToothGrowth$dose==0.5, 'len'],ToothGrowth[ToothGrowth$supp=="OJ"&ToothGrowth$dose==0.5, 'len'])
p
str(p)
t.test(ToothGrowth[ToothGrowth$supp=="OJ"&ToothGrowth$dose==1, 'len'],ToothGrowth[ToothGrowth$supp=="OJ"&ToothGrowth$dose==0.5, 'len'])$p.value
?float
?as.numeric
as.numeric(t.test(ToothGrowth[ToothGrowth$supp=="OJ"&ToothGrowth$dose==1, 'len'],ToothGrowth[ToothGrowth$supp=="OJ"&ToothGrowth$dose==0.5, 'len'])$p.value, length=5)
rmarkdown::render('in.md',
output_format=pdf_document(latex_engine='xelatex')
)
?stat_function
qt(.975, df=8)
qt(.025, df=8)
6/2.3
qt(.025)
library(datasets)
data(mtcars)
str(mtcars)
t.test(mtcars[mtcars$cyl==4, mpg], mtcars[mtcars$cyl==6, mpg])
t.test(mtcars[[mtcars$cyl==4, mpg]], mtcars[[mtcars$cyl==6, mpg]])
t.test(mtcars[mtcars$cyl==4, "mpg"], mtcars[mtcars$cyl==6, "mpg"])
qnorm(0.975)
3-qnorm(0.975)*1.1/10
3+qnorm(0.975)*1.1/10
dbinom(55,100,prob=0.5)
?dbinom
pbinom(55,100,prob=0.5)
pbinom(54,100,prob=0.5)
pbinom(54,100,prob=0.5, lower.tail=F)
?ppois
ppois(15800/30, 520. lower.tail=F)
ppois(15800/30, 520, lower.tail=F)
ppois(15800, 520*30, lower.tail=F)
10/(4*sqrt(2))
qnorm(1.76)
?qnorm
pnorm(1.76)
1-pnorm(1.76)
qnorm(0.95)
10+qnorm(0.95)*0.4
pnorm((11-10.65)/0.4, lower.tail=F)
pnorm((10.65-11)/0.4, lower.tail=F)
R.version.string
library(swirl)
swirl()
myplot(2)
myplot(20)
myplot2(2)
qt(.975, 2)
myplot2(20)
sleep
range
range(g1)
range(g2)
difference = g2-g1
difference <- g2-g1
mean(difference)
s <- sd(difference)
mn + c(-1, 1)*qt(0.975, 10)
mn + c(-1, 1)*qt(0.975, 9)*s/sqrt(10)
t.test(g1, g2)$conf.int.
t.test(difference)$conf.int.
t.test(difference)$conf.int
sp <- 7*15.34^2+20*18.23^2
ns <- 8+21-2
sp <- sqrt(sp/ns)
132.86-127.44 + c(-1,1)*qt(0.975, 27)*sp
132.86-127.44+c(-1,1)*qt(.975,ns)*sp*sqrt(1/8+1/21)
sp <- var(g1)+var(g2)
sp <- sqrt((9*var(g1)+9*var(g2))/18)
md + c(-1,1)*qt(0.975,18)*sp*sqrt(1/10+1/10)
t.test(g2,g1)$conf.int
t.test(g2,g1,paired=FALSE,var.equal=TRUE)$conf
t.test(g2,g1, paired=TRUE)
t.test(g2,g1, paired=TRUE)$conf
num <- (15.34^2/8)^2/(8-1)+(18.23^2/20)^2/(21-1)
num <- (15.34^2/8 + 18.23^2/21)^2
den <- (15.34^2/8)^2/(8-1)+(18.23^2/20)^2/(21-1)
den <- 15.34^4/8^2/7 + 18.23^4/21^2/20
mydf <- num/den
X'_{oc}-X'_{c} + c(-1, 1)*qt(0.975, mydf)*sqrt((s_1)^2/n_1+(s_2)^2/n_2)
X'_{oc}-X'_{c} + c(-1, 1)*qt(0.975, mydf)*sqrt((s_1)^2/n_1+(s_2)^2/n_2)
132.86-127.44 + c(-1, 1)*qt(0.975, mydf)*sqrt((s_1)^2/n_1+(s_2)^2/n_2)
132.86-127.44 + c(-1, 1)*qt(0.975, mydf)*sqrt(15.34^2/8+18.23^2/21)
1
2
0.8
15
qt(0.95, 15)
dim(fs)
t.test(fs$sheight, fs$fheight, paired=TRUE)
11.7885*sd(fs$sheight-fs$fheight)/sqrt(1078)
mybin
7
8
pt(2.5, df=15, lower.tail=F)
pt(2.5, 15, lower.tail=FALSE)
qnorm(0.95)
qnorm(0.99)
pnorm(2. lower.tail=TRUE)
pnorm(2, lower.tail=TRUE)
pnorm(2, lower.tail=FALSE)
mybin
pbinom(6, size=8, prob=0.5, lower.tail=FALSE)
pbinom(7, size=8, p=0.5, lower.tail=T)
pbinom(7, size=8, p=0.5, lower.tail=TRUE)
pbinom(5,9, lower.tail=FALSE)
pbinom(5,9, p=0.1, lower.tail=FALSE)
ppois(9,5,lower.tail=FALSE)
myplot(24)
myplot(34)
myplot(33.3)
myplot(30)
myplot(28)
z <- qnorm(.95)
pnorm(30+z, 20, 1, lower.tail=FALSE)
pnorm(30+z, 30, 1 lower.tail=FALSE)
pnorm(30+z, 30, 1, lower.tail=FALSE)
pnorm(30+z, 32, 1, lower.tail=FALSE)
pnorm(30+z, 32, 1, lower.tail=FALSE)
pnorm(30+z, 32, 2, lower.tail=FALSE)
pnorm(30+z*2, 32, 2, lower.tail=FALSE)
power.t.test(n=16, delta=2/4, sd=1, type="one.sample", alt="one.sided")$power
power.t.test(n=16, delta=2, sd=4, type="one.sample", alt="one.sided")$power
power.t.test(n=16, delta=100, sd=200, type="one.sample", alt="one.sided")$power
power.t.test(power=.8, delta=2/4, sd=1, type="one.sample", alt="one.sided")$n
power.t.test(power=.8, delta=2, sd=4, type="one.sample", alt="one.sided")$n
power.t.test(power=.8, delta=100, sd=200, type="one.sample", alt="one.sided")$n
power.t.test(power=.8,n=26,sd=1, type="one.sample", alt="one.sided")$delta
power.t.test(power=.8,n=27,sd=1, type="one.sample", alt="one.sided")$delta
g1 = c(140,138,150,148,135)
g2 = c(132,135,151,146,130)
?t.test
t.test(g1,g2)
t.test(g1,g2, paired=TRUE)
?qt
1100+c(-1,1)*qt(0.975, 8)*30/3
5/16
4*0.75^3*0.25+0.75^4
?ppois
ppois(10/1787, 1/100)
ppois(10/1787, 9/1000)
power.t.test(power=.9, delta=0.01, sd=0.04, type="one.sample", alt="one.sided")$n
qnorm(0.95)
(1.64*4)^2
qt(0.95)
power.t.test(n=100, delta=0.01, sd=.04,type="one.sample", alt="one.sided")$power
?t.test
t<- (-3-1)/sqrt(1.5^2/9+1.8^2/9)
qt(t, 16)
?qt
pt(t,16)
?ppois
qpois(0.52, 0.01)
qpois(0.52, 17.87)
ppois(10, 17.87)
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
library("devtools", lib.loc="~/R/win-library/3.1")
?manipulate
library(swirl)
swirl()
0
quit
quit()
library(swril)
library(swirl)
swirl()
plot(child~parent, galton)
plot(jitter(child, 4)~parent, galton)
regrline <- lm(child ~ parent, galton)
abline(regrline, lwd=3, col='red')
summary(regrline)
lm(child~parent, galton)
fit <- lm(child ~ parent, galton)
summary(fit)
mean(fit$residuals)
cov(fit$residuals, galton$parent)
ols.ic <- fit$coef
ols.ic <- fit$coef[1]
ols.slope <- fit$coef[2]
rhs-lhs
lhs-rhs
all.equal(lhs, rhs)
varChild <- var(child)
varChild <- var(galton$child)
varRes <- var(fit$residuals)
?est
varEst <- est(ols.slope, ols.ic)
varEst <- var(est(ols.slope, ols.ic))
varChild
all.equal(varChild, varEst+varRes)
efit <- lm(accel ~ mag+dist, attenu)
mean(efit$residuals)
cov(efit$residuals, attenu$mag)
cov(efit$residuals, attenu$dist)
library(devtools)
data(mtcars)
fit <- lm(mpg~wt, data = mtcars)
length(mtcars)
head(mtcars)
dim(mtcars)
sigma_hat <- sqrt(sum(fit$residues^2)/(9))*sqrt(1+1/11)
sigma_hat
sum(fit$residues^2)
summary(fit)
y_sigma <- 3.046*sqrt(1+1/32)
?predict
predict(fit, mean(mtcars$wt), 0.95, 'confidence intervals')
predict(fit, mean(mtcars$wt), level=0.95, interval='confidence')
predict(fit, mean(mtcars$wt), level=0.95, interval='prediction')
predict(fit, mtcars$wt, level=0.95, interval='prediction')
newData = data.frame(x=mean(mtcars$wt))
predict(fit, newData, level=0.95, interval='prediction')
newData = data.frame(x<-mtcars$wt)
predict(fit, newData, level=0.95, interval='prediction')
predict(fit, newData, (interval='prediction'))
predict(fit, newData, interval=('prediction'))
predict(fit, mtcars, interval=('prediction'))
1<- predict(fit, mtcars, interval=('prediction'))
x<- predict(fit, mtcars, interval=('prediction'))
mean(x[:,2])
x
mean(x[:,"lwr"])
mean(x[[,"lwr"]])
mean(x[[1:32,"lwr"]])
x[3,4]
x[3,3]
x[3:10,3]
x[1:32,2]
y<- x[1:32,2]
mean(y)
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(y~x)
fit$coefficients
summary(fit)
?qt
x <- c(1,2,3)
deviance(x)
?deviance
summary(fit)
deviance(fit)
sigma_hat <- sqrt(deviance(fit)/(fit$df.residual))
sigma_hat
fit$df.residual
data(mtcars)
fit_mtcars <- lm(mpg~wt, data=mtcars)
summary(fit_mtcars)
newdata <- data.frame(wt = mean(mtcars$wt))
predict(fit_mtcars, newdata, interval = 'predict')
mean(mtcars$mpg)
se_mpg <- sqrt(deviance(fit_mtcars)/(fit_mtcars$df.residual))*sqrt(1+1/32)
se_mpg
predict(fit_mtcars, newdata, interval = 'confidence')
help mtcars
predict(fit_mtcars, data.frame(wt=3), interval = 'confidence')
predict(fit_mtcars, data.frame(wt=3), interval = 'predict')
predict(fit_mtcars, data.frame(wt=2), interval = 'predict')
predict(fit_mtcars, data.frame(wt=2), interval = 'confidence')
fit_mtcars_shortton <- lm(mtcars$mpg ~ (mtcars$wt)/2)
x <- mtcars$mpg
ympg <- mtcars$mpg
xshortton <- (mtcars$wt)/2
fit_mtcars_shortton <- lm(ympg~xshortton)
summary(fit_mtcars_shortton)
?qt
-10.689-1.118*pt(-9.558, 30)
pt(-9.558, 30)
-10.689-1.118*pt(0.975, 30)
sumcoeff <- fit_mtcars_shortton$coefficients
sumcoeff[2,1] + c(-1, 1) * qt(.975, df = fit_mtcars_shortton$df) * sumcoeff[2, 2]
sumcoeff
sumcoeff <- summary(fit_mtcars_shortton)$coefficients
sumcoeff[2,1] + c(-1, 1) * qt(.975, df = fit_mtcars_shortton$df) * sumcoeff[2, 2]
sumcoeff
-10.689-1.118*qt(0.975, 30)
summary(fit_mtcars)
deviance(fit_mtcars)/sum((mtcars$mpg-mean(mtcars$mpg))^2)
library(datasets)
data(swiss)
require(stats)
require(graphics)
pairs(swiss, panel=panel.smooth, main="Swiss data", col=3+(swiss$Catholic>50))
summary(lm(Fertility~., data=swiss))
summary(lm(Fertility~Ariculture, data=swiss))$coefficients
summary(lm(Fertility~Ariculture, data=swiss))
summary(lm(Fertility~Agriculture, data=swiss))
library(ElemStatLearn)
install.packages("dplyr")
library(googleVis)
install.packages('googleVis')
library(googleVis)
M <- gvisMotionChart(Fruits, "Fruit", "Year", options = list(width = 600, height = 400))
print(M, 'chart')
print(M, "chart")
getwd()
library(devtools)
devtools::install_github('rstudio/shinyapps')
shinyapps::setAccountInfo(name='xinyutan', token='2ECDBB5ACD75E1AE03BEE5BFB7C247B0', secret='<SECRET>')
shinyapps::setAccountInfo(name='xinyutan', token='2ECDBB5ACD75E1AE03BEE5BFB7C247B0', secret='/GKvcD61+f0Vl5KEJRPV9SmEdiQw/gTfLFzVjusp')
34.82-9.49-6.99
18.34/2+51.64/2+68.90/2+51.55/2+587.90/2
18.93+14.76+20.41+61.71+43.44+46.43+15.19
220.87/2
389.165-110.435
library(slidify)
source("https://bioconductor.org/biocLite.R")
biocLite("RCytoscape")
x <- c(13461.8378818737	13543.8974151858	13409.1061519904	13512.0250097694	13339.1263282172	13386.9909126827	13336.4858934169	13229.0848982786	13364.4876325088	13308.3566978193	13300.4844720497	13284.0335260116	13460.6819938176	13242.5988483685	13386.4547892720	13275.3145038168	13337.2806083650	13410.3210205636	13411.6427492447	13489.7864701436	13409.7804054054	13291.3864063087	13375.3955838323	13663.7737827715	13564.6735074627	13721.1583862533	13617.6338553318	13656.6455460306	13622.5345982143	13636.1042671614	13696.6207917129	13359.8201705599	13651.4019316493	13434.3000739098	13394.8301886792	13360.7062292665	13518.9148544047	13444.0987836344	13375.6794258373	13543.4486803519	13684.6128796195	13630.8686905633	13499.4883381924	13455.5990531682	13531.5714805384
)
x <- 13461.8378818737	13543.8974151858	13409.1061519904	13512.0250097694	13339.1263282172	13386.9909126827	13336.4858934169	13229.0848982786	13364.4876325088	13308.3566978193	13300.4844720497	13284.0335260116	13460.6819938176	13242.5988483685	13386.4547892720	13275.3145038168	13337.2806083650	13410.3210205636	13411.6427492447	13489.7864701436	13409.7804054054	13291.3864063087	13375.3955838323	13663.7737827715	13564.6735074627	13721.1583862533	13617.6338553318	13656.6455460306	13622.5345982143	13636.1042671614	13696.6207917129	13359.8201705599	13651.4019316493	13434.3000739098	13394.8301886792	13360.7062292665	13518.9148544047	13444.0987836344	13375.6794258373	13543.4486803519	13684.6128796195	13630.8686905633	13499.4883381924	13455.5990531682	13531.5714805384
load("D:/Google Drive/KaggleProjects/Springleaf Marketing Response/xgboost on the whole data set.RData")
clf
.
data_file = 'D:/Google Drive/MichiganProjects/MDST_GGB/data/train_cleaned.csv'
library(caret)
target_file = 'D:/Google Drive/MichiganProjects/MDST_GGB/data/train_label.csv'
classes <- read.csv(target_file, nrows = 1000)
training <- read.csv(data_file, nrows = 1000)
training[1:5, 1814]
bag(training, classes, B = 10)
bag(training, classes, B = 10, bagControl = NULL)
?bag
bag(training, classes, B = 10, vars = ncol(training), bagControl = NULL)
testbag <- bag(training, classes, B = 10, vars = ncol(training), bagControl = bagControl(fit = ctreeBag$fit, predict = ctreeBag$pred, aggregate = ctreeBag$aggregate)
)
install.packages('party')
library(party)
testbag <- bag(training, classes, B = 10, vars = ncol(training), bagControl = bagControl(fit = ctreeBag$fit, predict = ctreeBag$pred, aggregate = ctreeBag$aggregate))
testbag <- bag(training, classes, B = 1000, vars = ncol(training), bagControl = bagControl(fit = ctreeBag$fit, predict = ctreeBag$pred, aggregate = ctreeBag$aggregate))
list(classes)
testbag <- bag(training, list(classes), B = 1000, vars = ncol(training), bagControl = bagControl(fit = ctreeBag$fit, predict = ctreeBag$pred, aggregate = ctreeBag$aggregate))
train <- read.csv('D:/Google Drive/KaggleProjects/Rossmann Store Sales/Data/train.csv/train.csv')
store <- read.csv('D:/Google Drive/KaggleProjects/Rossmann Store Sales/Data/store.csv/store.csv')
merged_train <- merge(train, store, by = 'Store')
write.csv(merged_train, file = 'D:/Google Drive/KaggleProjects/Rossmann Store Sales/Data/merged_train.csv')
View(merged_train)
View(train)
train <- read.csv('D:/Google Drive/KaggleProjects/Rossmann Store Sales/Data/train.csv/train.csv')
View(train)
View(train)
?sample
internal_train_idx <- sample(1:nrow(train), int(nrow(train))*0.75)
?integer
internal_train_idx <- sample(1:nrow(train), as.integer(nrow(train))*0.75)
?sample
internal_train <- train[internal_train_idx, ]
internal_test <- train[-internal_train_idx, ]
254303.0/1017209
rm interal_test
rm(interal_test)
rm(internal_test)
rm(internal_train)
rm(internal_train_idx)
set.seed(12345)
internal_train_idx <- sample(1:nrow(train), as.integer(nrow(train))*0.75)
internal_train <- train[internal_train_idx, ]
internal_test <- train[-internal_train_idx, ]
merged_internal_train <- merge(internal_train, store, by = 'Store')
store <- read.csv('D:/Google Drive/KaggleProjects/Rossmann Store Sales/Data/store.csv/store.csv')
merged_internal_train <- merge(internal_train, store, by = 'Store')
View(merged_internal_train)
write.csv(interal_train, file = 'D:/Google Drive/KaggleProjects/Rossmann Store Sales/Data/internalTrain.csv')
write.csv(interal_test, file = 'D:/Google Drive/KaggleProjects/Rossmann Store Sales/Data/internaltest.csv')
write.csv(merged_interal_train, file = 'D:/Google Drive/KaggleProjects/Rossmann Store Sales/Data/internalMergeTrain.csv')
write.csv(interal_train, file = 'D:/Google Drive/KaggleProjects/Rossmann Store Sales/Data/internalTrain.csv')
write.csv(interal_test, file = 'D:/Google Drive/KaggleProjects/Rossmann Store Sales/Data/internaltest.csv')
write.csv(merged_interal_train, file = 'D:/Google Drive/KaggleProjects/Rossmann Store Sales/Data/internalMergeTrain.csv')
write.csv(internal_train, file = 'D:/Google Drive/KaggleProjects/Rossmann Store Sales/Data/internalTrain.csv')
write.csv(internal_test, file = 'D:/Google Drive/KaggleProjects/Rossmann Store Sales/Data/internaltest.csv')
write.csv(merged_internal_train, file = 'D:/Google Drive/KaggleProjects/Rossmann Store Sales/Data/internalMergeTrain.csv')
setwd('D:/Google Drive/KaggleProjects/MDST Professor Ratings Anlysis/RMP-XT/ExploratoryAnalysis')
library(rJava)
install.packages(c("NLP", "openNLP", "RWeka", "qdap"))
train <- read.csv('../../Data/train.csv', header = T)
lappy(train, function(x) sum(is.na(x)))
lapply(train, function(x) sum(is.na(x)))
View(train)
?read.csv
x <- train$tags
x
sum(x == [])
sum(x == '[]')
train <- read.csv('../../Data/train.csv', header = T, na.strings = 'N/A'|'[]')
train <- read.csv('../../Data/train.csv', header = T, na.strings = c('N/A','[]'))
View(train)
lapply(train, function(x) sum(is.na(x)))
sapply(train, function(x) sum(is.na(x)))
sapply(train, function(x) sum(is.na(x)))/nrow(train)
x <- sapply(train, function(x) sum(is.na(x)))/nrow(train)
x['id']
